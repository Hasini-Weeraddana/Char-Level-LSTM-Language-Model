{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "063155ba-112c-4598-8a27-4eb92dc689f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0782b154-f9b4-4e98-808a-59edd589e273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "600901/600901 [==============================] - 2s 4us/step\n",
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = tf.keras.utils.get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path, encoding='utf-8').read().lower()\n",
    "print(f\"Corpus length: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4191b6-77ba-455b-a7e7-c9b7398650a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08c1809-eeb9-4453-afc6-54e78db159a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "# Create sequences\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print(f\"Number of sequences: {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a33f0ed-8f8e-431b-9dcf-c599569709d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool_)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool_)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0fcb8ef-98ba-42d8-ad62-09f7eedff251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1565/1565 [==============================] - 361s 216ms/step - loss: 2.5763\n",
      "Epoch 2/20\n",
      "1565/1565 [==============================] - 310s 198ms/step - loss: 2.2158\n",
      "Epoch 3/20\n",
      "1565/1565 [==============================] - 224s 143ms/step - loss: 2.0831\n",
      "Epoch 4/20\n",
      "1565/1565 [==============================] - 313s 200ms/step - loss: 1.9950\n",
      "Epoch 5/20\n",
      "1565/1565 [==============================] - 360s 230ms/step - loss: 1.9246\n",
      "Epoch 6/20\n",
      "1565/1565 [==============================] - 264s 169ms/step - loss: 1.8693\n",
      "Epoch 7/20\n",
      "1565/1565 [==============================] - 235s 150ms/step - loss: 1.8192\n",
      "Epoch 8/20\n",
      "1565/1565 [==============================] - 314s 201ms/step - loss: 1.7772\n",
      "Epoch 9/20\n",
      "1565/1565 [==============================] - 282s 180ms/step - loss: 1.7401\n",
      "Epoch 10/20\n",
      "1565/1565 [==============================] - 246s 157ms/step - loss: 1.7080\n",
      "Epoch 11/20\n",
      "1565/1565 [==============================] - 335s 214ms/step - loss: 1.6793\n",
      "Epoch 12/20\n",
      "1565/1565 [==============================] - 214s 137ms/step - loss: 1.6544\n",
      "Epoch 13/20\n",
      "1565/1565 [==============================] - 291s 186ms/step - loss: 1.6319\n",
      "Epoch 14/20\n",
      "1565/1565 [==============================] - 143s 92ms/step - loss: 1.6120\n",
      "Epoch 15/20\n",
      "1565/1565 [==============================] - 128s 82ms/step - loss: 1.5931\n",
      "Epoch 16/20\n",
      "1565/1565 [==============================] - 140s 89ms/step - loss: 1.5764\n",
      "Epoch 17/20\n",
      "1565/1565 [==============================] - 150s 96ms/step - loss: 1.5616\n",
      "Epoch 18/20\n",
      "1565/1565 [==============================] - 167s 107ms/step - loss: 1.5459\n",
      "Epoch 19/20\n",
      "1565/1565 [==============================] - 175s 112ms/step - loss: 1.5331\n",
      "Epoch 20/20\n",
      "1565/1565 [==============================] - 219s 140ms/step - loss: 1.5202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8f54b2fe0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(maxlen, len(chars))),\n",
    "    Dense(len(chars), activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "checkpoint = ModelCheckpoint('char_lm_model.h5', monitor='loss', save_best_only=True)\n",
    "model.fit(X, y, batch_size=128, epochs=20, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a00ed691-9f5c-4b19-acf1-4a60c2d74fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('char_lm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f844a8-0804-4ef1-88ac-513a0c17641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample the next character with temperature\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-8) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3740846a-c194-4692-a5e6-1b10cef8dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating with seed: 'lute philosophical edifices as the dogma'\n",
      "\n",
      "--- Temperature: 0.2\n",
      "lute philosophical edifices as the dogmative of the prost and the spirit the still the same a still to the strength of the strength of the spirit to the prost of the stands the prost still to the strength and the conscious and the strengle the fact the consciously and the still to the conscience of the strong and the sainted to the desire the most strength of the same and such a sortle the still to the actions and the called to the the \n",
      "\n",
      "--- Temperature: 0.5\n",
      "lute philosophical edifices as the dogmative of the prost and the spirit the still the same a still to the strength of the strength of the spirit to the prost of the stands the prost still to the strength and the conscious and the strengle the fact the consciously and the still to the conscience of the strong and the sainted to the desire the most strength of the same and such a sortle the still to the actions and the called to the the may men and with it is a surerlity and others and of the cases the strength, the individuality, and conscience the man be regard the short of the greated and all the present of the\n",
      "undare of his of the\n",
      "most man\n",
      "in the dolet the master in the selital such as the same that the prost of the still eastions and something the conscience of the same a still for the consciousle and spirit which the case o\n",
      "\n",
      "--- Temperature: 1.0\n",
      "lute philosophical edifices as the dogmative of the prost and the spirit the still the same a still to the strength of the strength of the spirit to the prost of the stands the prost still to the strength and the conscious and the strengle the fact the consciously and the still to the conscience of the strong and the sainted to the desire the most strength of the same and such a sortle the still to the actions and the called to the the may men and with it is a surerlity and others and of the cases the strength, the individuality, and conscience the man be regard the short of the greated and all the present of the\n",
      "undare of his of the\n",
      "most man\n",
      "in the dolet the master in the selital such as the same that the prost of the still eastions and something the conscience of the same a still for the consciousle and spirit which the case of no langacts history of thoughting and full\n",
      "the laitely, but their works.\"\" merehy\n",
      "pressudous his ofse to one is not speat, on the every pains im, the the exertace self--only phesent, of the everynove a sympathrage. who who\n",
      "how--phis\n",
      "slle perhaving brongerfoch with the unnectivem\" and daged and follern!\n",
      "                       112] ppollens in its, by thous thing) of sen, as the addantion: other; \n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "seed_text = text[1000:1040]\n",
    "generated = seed_text\n",
    "print(f\"\\nGenerating with seed: '{seed_text}'\")\n",
    "\n",
    "for temperature in [0.2, 0.5, 1.0]:\n",
    "    print(f\"\\n--- Temperature: {temperature}\")\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(seed_text):\n",
    "            sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        seed_text = seed_text[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f1d8a-bebb-4731-9df6-7f98ac3e16d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
